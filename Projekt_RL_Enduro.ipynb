{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#niezbędne biblioteki\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models     import Sequential\n",
    "from keras.layers     import Dense, Conv2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from skimage import color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('Enduro-v0')\n",
    "env.reset()\n",
    "goal_steps = 5000\n",
    "#score_requirement = 6000\n",
    "intial_games = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do zobaczenia informacji jakie zwraca nam gra\n",
    "def play_a_random_game_first():\n",
    "    for step_index in range(goal_steps):\n",
    "        #env.render()\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        print(\"Step {}:\".format(step_index))\n",
    "        print(\"action: {}\".format(action))\n",
    "        print(\"done: {}\".format(done))\n",
    "        if done:\n",
    "            break\n",
    "    env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcja do preprocesingu ramek. Ucinam górną część (niesitotne niebo) i zmieniam na czarno-biały obrazek\n",
    "def preprocces_frame(frame):\n",
    "    img = color.rgb2gray(frame)\n",
    "    img=img[50:,:]\n",
    "    img=img.reshape(img.shape[0], img.shape[1],-1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generowanie danych. Zapisuje tylko ścieżki, które dały dobry rezultat\n",
    "def model_data_preparation(require_score):\n",
    "    training_data = []\n",
    "    observations=[]\n",
    "    actions=[]\n",
    "    i=0\n",
    "    j=0\n",
    "    for game_index in range(intial_games):\n",
    "        score = 0\n",
    "        game_memory = []\n",
    "        previous_observation = []\n",
    "        for step_index in range(4300):\n",
    "            action = random.randrange(0, 9)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "        for step_index in range(goal_steps):\n",
    "            action = random.randrange(0, 9)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            if len(previous_observation) > 0:\n",
    "                game_memory.append([previous_observation, action])\n",
    "                \n",
    "            previous_observation = observation\n",
    "            score += 1\n",
    "            if done:\n",
    "                break\n",
    "        if score >= require_score:\n",
    "            print(\"Udało się\", j)\n",
    "            j+=1\n",
    "            for data in game_memory:\n",
    "                data[1]=np_utils.to_categorical(data[1],9).reshape(9)\n",
    "                data[0]= preprocces_frame(data[0])\n",
    "                observations.append(data[0])\n",
    "                actions.append(data[1])\n",
    "\n",
    "        env.reset()\n",
    "        print(i)\n",
    "        i+=1\n",
    "    \n",
    "    return [observations, actions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Udało się 0\n",
      "0\n",
      "1\n",
      "Udało się 1\n",
      "2\n",
      "Udało się 2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Udało się 3\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Udało się 4\n",
      "15\n",
      "16\n",
      "17\n",
      "Udało się 5\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "Udało się 6\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "Udało się 7\n",
      "52\n",
      "53\n",
      "Udało się 8\n",
      "54\n",
      "55\n",
      "56\n",
      "Udało się 9\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "Udało się 10\n",
      "62\n",
      "Udało się 11\n",
      "63\n",
      "64\n",
      "65\n",
      "Udało się 12\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "Udało się 13\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "Udało się 14\n",
      "88\n",
      "Udało się 15\n",
      "89\n",
      "Udało się 16\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "training_data = model_data_preparation(160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkcja do budowania modelu: prawdopodobnie będę generował i uczył model jednocześnie, by oszczędzić pamięć\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (3,3), input_shape=(160,160, 1), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(52, activation='relu'))\n",
    "    model.add(Dense(9, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer=Adam())\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(training_data):\n",
    "    X = np.array(training_data[0])\n",
    "    y = np.array(training_data[1])\n",
    "    model = build_model()\n",
    "    \n",
    "    model.fit(X, y, epochs=10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/arkadiusz/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/arkadiusz/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "2846/2846 [==============================] - 31s 11ms/step - loss: 0.3505\n",
      "Epoch 2/10\n",
      "2846/2846 [==============================] - 24s 9ms/step - loss: 0.0984\n",
      "Epoch 3/10\n",
      "2846/2846 [==============================] - 24s 9ms/step - loss: 0.0934\n",
      "Epoch 4/10\n",
      "2846/2846 [==============================] - 24s 9ms/step - loss: 0.0884\n",
      "Epoch 5/10\n",
      "2846/2846 [==============================] - 24s 9ms/step - loss: 0.0844\n",
      "Epoch 6/10\n",
      "2846/2846 [==============================] - 24s 9ms/step - loss: 0.0797\n",
      "Epoch 7/10\n",
      "2846/2846 [==============================] - 24s 9ms/step - loss: 0.0753\n",
      "Epoch 8/10\n",
      "2846/2846 [==============================] - 25s 9ms/step - loss: 0.0703\n",
      "Epoch 9/10\n",
      "2846/2846 [==============================] - 25s 9ms/step - loss: 0.0663\n",
      "Epoch 10/10\n",
      "2846/2846 [==============================] - 25s 9ms/step - loss: 0.0619\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4464, 4408, 4444, 4397, 4435]\n",
      "Average Score: 4429.6\n"
     ]
    }
   ],
   "source": [
    "#Testowanie\n",
    "scores = []\n",
    "#choices = []\n",
    "for each_game in range(5):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(goal_steps):\n",
    "        #env.render()\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(trained_model.predict(prev_obs.reshape(-1, prev_obs.shape[0], prev_obs.shape[1],\n",
    "                                                                      prev_obs.shape[2])))\n",
    "        \n",
    "        #choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = preprocces_frame(new_observation)\n",
    "        score+=1\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "\n",
    "print(scores)\n",
    "print('Average Score:', sum(scores)/len(scores))\n",
    "#print('choice 1:{}  choice 0:{}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4464, 4425, 4404, 4410, 4443, 4429, 4433, 4406, 4459, 4447, 4414, 4438, 4484, 4421, 4426, 4438, 4447, 4452, 4463, 4453]\n",
      "Average Score: 4437.8\n"
     ]
    }
   ],
   "source": [
    "#Dla porównania losowe ruchy\n",
    "scores = []\n",
    "#choices = []\n",
    "for each_game in range(20):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(goal_steps):\n",
    "        #env.render()\n",
    "        action = random.randrange(0,8)\n",
    "        \n",
    "        #choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        score+=1\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "\n",
    "print(scores)\n",
    "print('Average Score:', sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
