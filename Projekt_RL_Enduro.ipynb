{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#niezbędne biblioteki\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models     import Sequential\n",
    "from keras.layers     import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from skimage import color\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [ 24,  26, 167],\n",
       "        [ 24,  26, 167],\n",
       "        [ 24,  26, 167]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [ 24,  26, 167],\n",
       "        [ 24,  26, 167],\n",
       "        [ 24,  26, 167]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [ 24,  26, 167],\n",
       "        [ 24,  26, 167],\n",
       "        [ 24,  26, 167]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('Enduro-v0')\n",
    "env.reset()\n",
    "#obs=env.reset()\n",
    "#preprocess_frame(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do zobaczenia informacji jakie zwraca nam gra\n",
    "def play_a_random_game_first():\n",
    "    for step_index in range(1500):\n",
    "        env.render()\n",
    "        if step_index==0:\n",
    "            action=random.randint(1,3)\n",
    "        else:\n",
    "            action = agent.model.predict(observation)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        observation = preprocess_frame(observation)\n",
    "        print(\"Step {}:\".format(step_index))\n",
    "        print(\"action: {}\".format(action))\n",
    "        print(\"reward:{}\".format(reward))\n",
    "        print(\"done: {}\".format(done))\n",
    "        print(\"info: {}\".format(info))\n",
    "        if done:\n",
    "            break\n",
    "env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0:\n",
      "action: 1\n",
      "reward:0.0\n",
      "done: False\n",
      "info: {'ale.lives': 0}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-0419adddd574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplay_a_random_game_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-51f78cee0fb3>\u001b[0m in \u001b[0;36mplay_a_random_game_first\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step {}:\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gym/envs/atari/atari_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_action_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "play_a_random_game_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcja do preprocesingu ramek. Ucinam górną część (niesitotne niebo) i zmieniam na czarno-biały obrazek\n",
    "def preprocess_frame(frame):\n",
    "    img = color.rgb2gray(frame)\n",
    "    img=img[50:155,20:140]\n",
    "    img=img.reshape(-1, img.shape[0], img.shape[1], 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size):\n",
    "        self.state_size = state_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(30, (3,3), strides=2, input_shape=(105, 120, 1), activation='elu'))\n",
    "        model.add(MaxPooling2D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dense(3, activation='linear'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randint(1,3)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])+1  # returns action\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * \\\n",
    "                       np.amax(self.model.predict(next_state)[0])\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action-1] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/500, score: 1820.0\n",
      "episode: 1/500, score: 1640.0\n",
      "episode: 2/500, score: 1590.0\n",
      "episode: 3/500, score: 1644.0\n",
      "episode: 4/500, score: 1432.0\n",
      "episode: 5/500, score: 1710.0\n",
      "episode: 6/500, score: 1772.0\n",
      "episode: 7/500, score: 1742.0\n",
      "episode: 8/500, score: 1826.0\n",
      "episode: 9/500, score: 1932.0\n",
      "episode: 10/500, score: 1880.0\n",
      "episode: 11/500, score: 1924.0\n",
      "episode: 12/500, score: 1900.0\n",
      "episode: 13/500, score: 1920.0\n",
      "episode: 14/500, score: 1870.0\n",
      "episode: 15/500, score: 1584.0\n",
      "episode: 16/500, score: 2042.0\n",
      "episode: 17/500, score: 1484.0\n",
      "episode: 18/500, score: 2082.0\n",
      "episode: 19/500, score: 1760.0\n",
      "episode: 20/500, score: 2084.0\n",
      "episode: 21/500, score: 1972.0\n",
      "episode: 22/500, score: 1902.0\n",
      "episode: 23/500, score: 1896.0\n",
      "episode: 24/500, score: 1852.0\n",
      "episode: 25/500, score: 2302.0\n",
      "episode: 26/500, score: 2132.0\n",
      "episode: 27/500, score: 2094.0\n",
      "episode: 28/500, score: 2122.0\n",
      "episode: 29/500, score: 1976.0\n",
      "episode: 30/500, score: 2070.0\n",
      "episode: 31/500, score: 2122.0\n",
      "episode: 32/500, score: 2078.0\n",
      "episode: 33/500, score: 2262.0\n",
      "episode: 34/500, score: 2064.0\n",
      "episode: 35/500, score: 2152.0\n",
      "episode: 36/500, score: 2162.0\n",
      "episode: 37/500, score: 2066.0\n",
      "episode: 38/500, score: 2276.0\n",
      "episode: 39/500, score: 2362.0\n",
      "episode: 40/500, score: 2218.0\n",
      "episode: 41/500, score: 2212.0\n",
      "episode: 42/500, score: 2276.0\n",
      "episode: 43/500, score: 2114.0\n",
      "episode: 44/500, score: 2386.0\n",
      "episode: 45/500, score: 2192.0\n",
      "episode: 46/500, score: 2442.0\n",
      "episode: 47/500, score: 2390.0\n",
      "episode: 48/500, score: 2374.0\n",
      "episode: 49/500, score: 2154.0\n",
      "episode: 50/500, score: 2396.0\n",
      "episode: 51/500, score: 2180.0\n",
      "episode: 52/500, score: 1350.0\n",
      "episode: 53/500, score: 2332.0\n",
      "episode: 54/500, score: 2524.0\n",
      "episode: 55/500, score: 2510.0\n",
      "episode: 56/500, score: 2556.0\n",
      "episode: 57/500, score: 2358.0\n",
      "episode: 58/500, score: 2464.0\n",
      "episode: 59/500, score: 2458.0\n",
      "episode: 60/500, score: 2450.0\n",
      "episode: 61/500, score: 2408.0\n",
      "episode: 62/500, score: 1300.0\n",
      "episode: 63/500, score: 2400.0\n",
      "episode: 64/500, score: 2358.0\n",
      "episode: 65/500, score: 2634.0\n",
      "episode: 66/500, score: 2674.0\n",
      "episode: 67/500, score: 2550.0\n",
      "episode: 68/500, score: 2394.0\n",
      "episode: 69/500, score: 2602.0\n",
      "episode: 70/500, score: 1090.0\n",
      "episode: 71/500, score: 2790.0\n",
      "episode: 72/500, score: 2624.0\n",
      "episode: 73/500, score: 2604.0\n",
      "episode: 74/500, score: 1300.0\n",
      "episode: 75/500, score: 2664.0\n",
      "episode: 76/500, score: 2516.0\n",
      "episode: 77/500, score: 2618.0\n",
      "episode: 78/500, score: 2636.0\n",
      "episode: 79/500, score: 2716.0\n",
      "episode: 80/500, score: 2970.0\n",
      "episode: 81/500, score: 2808.0\n",
      "episode: 82/500, score: 2960.0\n",
      "episode: 83/500, score: 2718.0\n",
      "episode: 84/500, score: 2600.0\n",
      "episode: 85/500, score: 2784.0\n",
      "episode: 86/500, score: 2642.0\n",
      "episode: 87/500, score: 2746.0\n",
      "episode: 88/500, score: 2734.0\n",
      "episode: 89/500, score: 2944.0\n",
      "episode: 90/500, score: 3062.0\n",
      "episode: 91/500, score: 2984.0\n",
      "episode: 92/500, score: 3050.0\n",
      "episode: 93/500, score: 2708.0\n",
      "episode: 94/500, score: 2796.0\n",
      "episode: 95/500, score: 2912.0\n",
      "episode: 96/500, score: 920.0\n",
      "episode: 97/500, score: 2868.0\n",
      "episode: 98/500, score: 3018.0\n",
      "episode: 99/500, score: 2982.0\n",
      "episode: 100/500, score: 2976.0\n",
      "episode: 101/500, score: 2932.0\n",
      "episode: 102/500, score: 2922.0\n",
      "episode: 103/500, score: 2906.0\n",
      "episode: 104/500, score: 2754.0\n",
      "episode: 105/500, score: 2984.0\n",
      "episode: 106/500, score: 2936.0\n",
      "episode: 107/500, score: 3064.0\n",
      "episode: 108/500, score: 2986.0\n",
      "episode: 109/500, score: 3074.0\n",
      "episode: 110/500, score: 2908.0\n",
      "episode: 111/500, score: 2944.0\n",
      "episode: 112/500, score: 2808.0\n",
      "episode: 113/500, score: 3040.0\n",
      "episode: 114/500, score: 2854.0\n",
      "episode: 115/500, score: 3020.0\n",
      "episode: 116/500, score: 3004.0\n",
      "episode: 117/500, score: 2974.0\n",
      "episode: 118/500, score: 2932.0\n",
      "episode: 119/500, score: 3026.0\n",
      "episode: 120/500, score: 3176.0\n",
      "episode: 121/500, score: 3242.0\n",
      "episode: 122/500, score: 3178.0\n",
      "episode: 123/500, score: 820.0\n",
      "episode: 124/500, score: 3044.0\n",
      "episode: 125/500, score: 3196.0\n",
      "episode: 126/500, score: 3098.0\n",
      "episode: 127/500, score: 3104.0\n",
      "episode: 128/500, score: 820.0\n",
      "episode: 129/500, score: 3234.0\n",
      "episode: 130/500, score: 3254.0\n",
      "episode: 131/500, score: 3242.0\n",
      "episode: 132/500, score: 3358.0\n",
      "episode: 133/500, score: 3260.0\n",
      "episode: 134/500, score: 3262.0\n",
      "episode: 135/500, score: 3236.0\n",
      "episode: 136/500, score: 3256.0\n",
      "episode: 137/500, score: 3138.0\n",
      "episode: 138/500, score: 3198.0\n",
      "episode: 139/500, score: 3150.0\n",
      "episode: 140/500, score: 3334.0\n",
      "episode: 141/500, score: 3108.0\n",
      "episode: 142/500, score: 3360.0\n",
      "episode: 143/500, score: 3420.0\n",
      "episode: 144/500, score: 3282.0\n",
      "episode: 145/500, score: 3256.0\n",
      "episode: 146/500, score: 3300.0\n",
      "episode: 147/500, score: 3368.0\n",
      "episode: 148/500, score: 3366.0\n",
      "episode: 149/500, score: 3216.0\n",
      "episode: 150/500, score: 3288.0\n",
      "episode: 151/500, score: 3386.0\n",
      "episode: 152/500, score: 3138.0\n",
      "episode: 153/500, score: 3448.0\n",
      "episode: 154/500, score: 3328.0\n",
      "episode: 155/500, score: 3350.0\n",
      "episode: 156/500, score: 680.0\n",
      "episode: 157/500, score: 3240.0\n",
      "episode: 158/500, score: 3626.0\n",
      "episode: 159/500, score: 3398.0\n",
      "episode: 160/500, score: 3486.0\n",
      "episode: 161/500, score: 3260.0\n",
      "episode: 162/500, score: 3398.0\n",
      "episode: 163/500, score: 3508.0\n",
      "episode: 164/500, score: 3518.0\n",
      "episode: 165/500, score: 3354.0\n",
      "episode: 166/500, score: 3542.0\n",
      "episode: 167/500, score: 3574.0\n",
      "episode: 168/500, score: 790.0\n",
      "episode: 169/500, score: 3430.0\n",
      "episode: 170/500, score: 3786.0\n",
      "episode: 171/500, score: 3184.0\n",
      "episode: 172/500, score: 3486.0\n",
      "episode: 173/500, score: 3474.0\n",
      "episode: 174/500, score: 3692.0\n",
      "episode: 175/500, score: 3762.0\n",
      "episode: 176/500, score: 3668.0\n",
      "episode: 177/500, score: 3418.0\n",
      "episode: 178/500, score: 3646.0\n",
      "episode: 179/500, score: 3524.0\n",
      "episode: 180/500, score: 3584.0\n",
      "episode: 181/500, score: 3678.0\n",
      "episode: 182/500, score: 3636.0\n",
      "episode: 183/500, score: 3458.0\n",
      "episode: 184/500, score: 3602.0\n",
      "episode: 185/500, score: 3708.0\n",
      "episode: 186/500, score: 3640.0\n",
      "episode: 187/500, score: 3686.0\n",
      "episode: 188/500, score: 3576.0\n",
      "episode: 189/500, score: 600.0\n",
      "episode: 190/500, score: 3552.0\n",
      "episode: 191/500, score: 3706.0\n",
      "episode: 192/500, score: 3644.0\n",
      "episode: 193/500, score: 3428.0\n",
      "episode: 194/500, score: 3674.0\n",
      "episode: 195/500, score: 3510.0\n",
      "episode: 196/500, score: 3666.0\n",
      "episode: 197/500, score: 3646.0\n",
      "episode: 198/500, score: 3726.0\n",
      "episode: 199/500, score: 3536.0\n",
      "episode: 200/500, score: 3816.0\n",
      "episode: 201/500, score: 3662.0\n",
      "episode: 202/500, score: 3820.0\n",
      "episode: 203/500, score: 3790.0\n",
      "episode: 204/500, score: 3806.0\n",
      "episode: 205/500, score: 3928.0\n",
      "episode: 206/500, score: 3792.0\n",
      "episode: 207/500, score: 3782.0\n",
      "episode: 208/500, score: 3548.0\n",
      "episode: 209/500, score: 3856.0\n",
      "episode: 210/500, score: 3666.0\n",
      "episode: 211/500, score: 3814.0\n",
      "episode: 212/500, score: 3584.0\n",
      "episode: 213/500, score: 3796.0\n",
      "episode: 214/500, score: 3802.0\n",
      "episode: 215/500, score: 3716.0\n",
      "episode: 216/500, score: 3690.0\n",
      "episode: 217/500, score: 3866.0\n",
      "episode: 218/500, score: 3702.0\n",
      "episode: 219/500, score: 4038.0\n",
      "episode: 220/500, score: 3802.0\n",
      "episode: 221/500, score: 3820.0\n",
      "episode: 222/500, score: 3732.0\n",
      "episode: 223/500, score: 3816.0\n",
      "episode: 224/500, score: 3834.0\n",
      "episode: 225/500, score: 3850.0\n",
      "episode: 226/500, score: 3592.0\n",
      "episode: 227/500, score: 520.0\n",
      "episode: 228/500, score: 3706.0\n",
      "episode: 229/500, score: 3852.0\n",
      "episode: 230/500, score: 3878.0\n",
      "episode: 231/500, score: 3868.0\n",
      "episode: 232/500, score: 3850.0\n",
      "episode: 233/500, score: 3872.0\n",
      "episode: 234/500, score: 3982.0\n",
      "episode: 235/500, score: 3958.0\n",
      "episode: 236/500, score: 3830.0\n",
      "episode: 237/500, score: 4056.0\n",
      "episode: 238/500, score: 3990.0\n",
      "episode: 239/500, score: 3854.0\n",
      "episode: 240/500, score: 3952.0\n",
      "episode: 241/500, score: 4028.0\n",
      "episode: 242/500, score: 3872.0\n",
      "episode: 243/500, score: 3908.0\n",
      "episode: 244/500, score: 4016.0\n",
      "episode: 245/500, score: 4078.0\n",
      "episode: 246/500, score: 3852.0\n",
      "episode: 247/500, score: 3994.0\n",
      "episode: 248/500, score: 3914.0\n",
      "episode: 249/500, score: 3968.0\n",
      "episode: 250/500, score: 3874.0\n",
      "episode: 251/500, score: 4048.0\n",
      "episode: 252/500, score: 3792.0\n",
      "episode: 253/500, score: 3908.0\n",
      "episode: 254/500, score: 3982.0\n",
      "episode: 255/500, score: 3994.0\n",
      "episode: 256/500, score: 3872.0\n",
      "episode: 257/500, score: 3988.0\n",
      "episode: 258/500, score: 4092.0\n",
      "episode: 259/500, score: 4010.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 260/500, score: 3972.0\n",
      "episode: 261/500, score: 4086.0\n",
      "episode: 262/500, score: 4056.0\n",
      "episode: 263/500, score: 3814.0\n",
      "episode: 264/500, score: 3994.0\n",
      "episode: 265/500, score: 4022.0\n",
      "episode: 266/500, score: 4008.0\n",
      "episode: 267/500, score: 3906.0\n",
      "episode: 268/500, score: 3868.0\n",
      "episode: 269/500, score: 4048.0\n",
      "episode: 270/500, score: 4084.0\n",
      "episode: 271/500, score: 4158.0\n",
      "episode: 272/500, score: 3900.0\n",
      "episode: 273/500, score: 4018.0\n",
      "episode: 274/500, score: 4100.0\n",
      "episode: 275/500, score: 4160.0\n",
      "episode: 276/500, score: 3990.0\n",
      "episode: 277/500, score: 4116.0\n",
      "episode: 278/500, score: 3816.0\n",
      "episode: 279/500, score: 4138.0\n",
      "episode: 280/500, score: 4118.0\n",
      "episode: 281/500, score: 4082.0\n",
      "episode: 282/500, score: 4058.0\n",
      "episode: 283/500, score: 4198.0\n",
      "episode: 284/500, score: 4310.0\n",
      "episode: 285/500, score: 3852.0\n",
      "episode: 286/500, score: 3972.0\n",
      "episode: 287/500, score: 4114.0\n",
      "episode: 288/500, score: 4070.0\n",
      "episode: 289/500, score: 4128.0\n",
      "episode: 290/500, score: 4086.0\n",
      "episode: 291/500, score: 4154.0\n",
      "episode: 292/500, score: 4160.0\n",
      "episode: 293/500, score: 4200.0\n",
      "episode: 294/500, score: 4118.0\n",
      "episode: 295/500, score: 4240.0\n",
      "episode: 296/500, score: 4240.0\n",
      "episode: 297/500, score: 4172.0\n",
      "episode: 298/500, score: 4072.0\n",
      "episode: 299/500, score: 4162.0\n",
      "episode: 300/500, score: 4230.0\n",
      "episode: 301/500, score: 4208.0\n",
      "episode: 302/500, score: 4256.0\n",
      "episode: 303/500, score: 4280.0\n",
      "episode: 304/500, score: 3944.0\n",
      "episode: 305/500, score: 4236.0\n",
      "episode: 306/500, score: 4118.0\n",
      "episode: 307/500, score: 4150.0\n",
      "episode: 308/500, score: 4158.0\n",
      "episode: 309/500, score: 4114.0\n",
      "episode: 310/500, score: 4380.0\n",
      "episode: 311/500, score: 4240.0\n",
      "episode: 312/500, score: 4256.0\n",
      "episode: 313/500, score: 4292.0\n",
      "episode: 314/500, score: 4264.0\n",
      "episode: 315/500, score: 4290.0\n",
      "episode: 316/500, score: 4148.0\n",
      "episode: 317/500, score: 4228.0\n",
      "episode: 318/500, score: 4070.0\n",
      "episode: 319/500, score: 4262.0\n",
      "episode: 320/500, score: 4092.0\n",
      "episode: 321/500, score: 4134.0\n",
      "episode: 322/500, score: 4282.0\n",
      "episode: 323/500, score: 4282.0\n",
      "episode: 324/500, score: 4266.0\n",
      "episode: 325/500, score: 4126.0\n",
      "episode: 326/500, score: 200.0\n",
      "episode: 327/500, score: 4160.0\n",
      "episode: 328/500, score: 4316.0\n",
      "episode: 329/500, score: 4276.0\n",
      "episode: 330/500, score: 4224.0\n",
      "episode: 331/500, score: 4166.0\n",
      "episode: 332/500, score: 4196.0\n",
      "episode: 333/500, score: 4260.0\n",
      "episode: 334/500, score: 290.0\n",
      "episode: 335/500, score: 4132.0\n",
      "episode: 336/500, score: 4360.0\n",
      "episode: 337/500, score: 4484.0\n",
      "episode: 338/500, score: 4272.0\n",
      "episode: 339/500, score: 4274.0\n",
      "episode: 340/500, score: 4360.0\n",
      "episode: 341/500, score: 4312.0\n",
      "episode: 342/500, score: 4366.0\n",
      "episode: 343/500, score: 4240.0\n",
      "episode: 344/500, score: 4286.0\n",
      "episode: 345/500, score: 4288.0\n",
      "episode: 346/500, score: 4446.0\n",
      "episode: 347/500, score: 4382.0\n",
      "episode: 348/500, score: 4224.0\n",
      "episode: 349/500, score: 4328.0\n",
      "episode: 350/500, score: 4292.0\n",
      "episode: 351/500, score: 4360.0\n",
      "episode: 352/500, score: 4384.0\n",
      "episode: 353/500, score: 4234.0\n",
      "episode: 354/500, score: 4296.0\n",
      "episode: 355/500, score: 4308.0\n",
      "episode: 356/500, score: 4348.0\n",
      "episode: 357/500, score: 4302.0\n",
      "episode: 358/500, score: 4340.0\n",
      "episode: 359/500, score: 4306.0\n",
      "episode: 360/500, score: 4326.0\n",
      "episode: 361/500, score: 4368.0\n",
      "episode: 362/500, score: 4284.0\n",
      "episode: 363/500, score: 4444.0\n",
      "episode: 364/500, score: 4366.0\n",
      "episode: 365/500, score: 4334.0\n",
      "episode: 366/500, score: 4368.0\n",
      "episode: 367/500, score: 4330.0\n",
      "episode: 368/500, score: 4340.0\n",
      "episode: 369/500, score: 4282.0\n",
      "episode: 370/500, score: 4520.0\n",
      "episode: 371/500, score: 4270.0\n",
      "episode: 372/500, score: 4422.0\n",
      "episode: 373/500, score: 4380.0\n",
      "episode: 374/500, score: 4370.0\n",
      "episode: 375/500, score: 4398.0\n",
      "episode: 376/500, score: 4376.0\n",
      "episode: 377/500, score: 4516.0\n",
      "episode: 378/500, score: 4422.0\n",
      "episode: 379/500, score: 4280.0\n",
      "episode: 380/500, score: 4486.0\n",
      "episode: 381/500, score: 4356.0\n",
      "episode: 382/500, score: 4462.0\n",
      "episode: 383/500, score: 4398.0\n",
      "episode: 384/500, score: 4474.0\n",
      "episode: 385/500, score: 4456.0\n",
      "episode: 386/500, score: 4420.0\n",
      "episode: 387/500, score: 4440.0\n",
      "episode: 388/500, score: 4270.0\n",
      "episode: 389/500, score: 4562.0\n",
      "episode: 390/500, score: 4494.0\n",
      "episode: 391/500, score: 4396.0\n",
      "episode: 392/500, score: 4458.0\n",
      "episode: 393/500, score: 4460.0\n",
      "episode: 394/500, score: 4370.0\n",
      "episode: 395/500, score: 4412.0\n",
      "episode: 396/500, score: 4532.0\n",
      "episode: 397/500, score: 4306.0\n",
      "episode: 398/500, score: 4510.0\n",
      "episode: 399/500, score: 4556.0\n",
      "episode: 400/500, score: 4460.0\n",
      "episode: 401/500, score: 4408.0\n",
      "episode: 402/500, score: 4446.0\n",
      "episode: 403/500, score: 4480.0\n",
      "episode: 404/500, score: 4488.0\n",
      "episode: 405/500, score: 4472.0\n",
      "episode: 406/500, score: 4420.0\n",
      "episode: 407/500, score: 4504.0\n",
      "episode: 408/500, score: 4586.0\n",
      "episode: 409/500, score: 4470.0\n",
      "episode: 410/500, score: 4306.0\n",
      "episode: 411/500, score: 4574.0\n",
      "episode: 412/500, score: 4522.0\n",
      "episode: 413/500, score: 4532.0\n",
      "episode: 414/500, score: 4452.0\n",
      "episode: 415/500, score: 4384.0\n",
      "episode: 416/500, score: 4588.0\n",
      "episode: 417/500, score: 4406.0\n",
      "episode: 418/500, score: 4454.0\n",
      "episode: 419/500, score: 4490.0\n",
      "episode: 420/500, score: 4500.0\n",
      "episode: 421/500, score: 4610.0\n",
      "episode: 422/500, score: 4562.0\n",
      "episode: 423/500, score: 4412.0\n",
      "episode: 424/500, score: 4496.0\n",
      "episode: 425/500, score: 4406.0\n",
      "episode: 426/500, score: 4484.0\n",
      "episode: 427/500, score: 4578.0\n",
      "episode: 428/500, score: 4506.0\n",
      "episode: 429/500, score: 4496.0\n",
      "episode: 430/500, score: 4606.0\n",
      "episode: 431/500, score: 4582.0\n",
      "episode: 432/500, score: 4440.0\n",
      "episode: 433/500, score: 4470.0\n",
      "episode: 434/500, score: 4308.0\n",
      "episode: 435/500, score: 4430.0\n",
      "episode: 436/500, score: 4524.0\n",
      "episode: 437/500, score: 4512.0\n",
      "episode: 438/500, score: 4572.0\n",
      "episode: 439/500, score: 4490.0\n",
      "episode: 440/500, score: 4520.0\n",
      "episode: 441/500, score: 4532.0\n",
      "episode: 442/500, score: 4558.0\n",
      "episode: 443/500, score: 4498.0\n",
      "episode: 444/500, score: 4570.0\n",
      "episode: 445/500, score: 4480.0\n",
      "episode: 446/500, score: 4572.0\n",
      "episode: 447/500, score: 4436.0\n",
      "episode: 448/500, score: 4536.0\n",
      "episode: 449/500, score: 4510.0\n",
      "episode: 450/500, score: 4634.0\n",
      "episode: 451/500, score: 4520.0\n",
      "episode: 452/500, score: 4522.0\n",
      "episode: 453/500, score: 4640.0\n",
      "episode: 454/500, score: 4512.0\n",
      "episode: 455/500, score: 4556.0\n",
      "episode: 456/500, score: 4630.0\n",
      "episode: 457/500, score: 4622.0\n",
      "episode: 458/500, score: 4560.0\n",
      "episode: 459/500, score: 4688.0\n",
      "episode: 460/500, score: 4568.0\n",
      "episode: 461/500, score: 4632.0\n",
      "episode: 462/500, score: 4576.0\n",
      "episode: 463/500, score: 4514.0\n",
      "episode: 464/500, score: 4552.0\n",
      "episode: 465/500, score: 4516.0\n",
      "episode: 466/500, score: 4516.0\n",
      "episode: 467/500, score: 4642.0\n",
      "episode: 468/500, score: 4604.0\n",
      "episode: 469/500, score: 4570.0\n",
      "episode: 470/500, score: 4620.0\n",
      "episode: 471/500, score: 4580.0\n",
      "episode: 472/500, score: 4662.0\n",
      "episode: 473/500, score: 4518.0\n",
      "episode: 474/500, score: 4620.0\n",
      "episode: 475/500, score: 4604.0\n",
      "episode: 476/500, score: 4624.0\n",
      "episode: 477/500, score: 4678.0\n",
      "episode: 478/500, score: 4596.0\n",
      "episode: 479/500, score: 4538.0\n",
      "episode: 480/500, score: 4470.0\n",
      "episode: 481/500, score: 4646.0\n",
      "episode: 482/500, score: 4500.0\n",
      "episode: 483/500, score: 4588.0\n",
      "episode: 484/500, score: 4712.0\n",
      "episode: 485/500, score: 4800.0\n",
      "episode: 486/500, score: 4544.0\n",
      "episode: 487/500, score: 4594.0\n",
      "episode: 488/500, score: 4594.0\n",
      "episode: 489/500, score: 4608.0\n",
      "episode: 490/500, score: 4584.0\n",
      "episode: 491/500, score: 4540.0\n",
      "episode: 492/500, score: 4580.0\n",
      "episode: 493/500, score: 4686.0\n",
      "episode: 494/500, score: 4624.0\n",
      "episode: 495/500, score: 4566.0\n",
      "episode: 496/500, score: 4690.0\n",
      "episode: 497/500, score: 4418.0\n",
      "episode: 498/500, score: 4622.0\n",
      "episode: 499/500, score: 4710.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # initialize gym environment and the agent\n",
    "    env = gym.make('Enduro-v0')\n",
    "    agent = DQNAgent(env)\n",
    "    episodes=500\n",
    "    # Iterate the game\n",
    "    for e in range(episodes):\n",
    "        score = 0\n",
    "        # reset state in the beginning of each game\n",
    "        state = env.reset()\n",
    "        state = preprocess_frame(state)\n",
    "        for time_t in range(500):\n",
    "            # turn this on if you want to render\n",
    "            # env.render()\n",
    "            # Decide action\n",
    "            action = agent.act(state)\n",
    "            # Advance the game to the next frame based on the action.\n",
    "            # Reward is 1 for every frame the pole survived\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            if action==1:\n",
    "                reward=reward+1\n",
    "            if reward==-1:\n",
    "                reward=-30\n",
    "            if reward==1:\n",
    "                reward=10\n",
    "            score=score+reward\n",
    "            next_state = preprocess_frame(next_state)\n",
    "            # Remember the previous state, action, reward, and done\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            # make next_state the new current state for the next frame.\n",
    "            state = next_state\n",
    "            # done becomes True when the game ends\n",
    "            # ex) The agent drops the pole\n",
    "            if done or time_t==499:\n",
    "                # print the score and break out of the loop\n",
    "                print(\"episode: {}/{}, score: {}\"\n",
    "                      .format(e, episodes, score))\n",
    "                break\n",
    "        # train the agent with the experience of the episode\n",
    "        agent.replay(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Udało się 0\n",
      "0\n",
      "1\n",
      "Udało się 1\n",
      "2\n",
      "Udało się 2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Udało się 3\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Udało się 4\n",
      "15\n",
      "16\n",
      "17\n",
      "Udało się 5\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "Udało się 6\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "Udało się 7\n",
      "52\n",
      "53\n",
      "Udało się 8\n",
      "54\n",
      "55\n",
      "56\n",
      "Udało się 9\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "Udało się 10\n",
      "62\n",
      "Udało się 11\n",
      "63\n",
      "64\n",
      "65\n",
      "Udało się 12\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "Udało się 13\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "Udało się 14\n",
      "88\n",
      "Udało się 15\n",
      "89\n",
      "Udało się 16\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/arkadiusz/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/arkadiusz/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "2846/2846 [==============================] - 31s 11ms/step - loss: 0.3505\n",
      "Epoch 2/10\n",
      "2846/2846 [==============================] - 24s 9ms/step - loss: 0.0984\n",
      "Epoch 3/10\n",
      "2846/2846 [==============================] - 24s 9ms/step - loss: 0.0934\n",
      "Epoch 4/10\n",
      "2846/2846 [==============================] - 24s 9ms/step - loss: 0.0884\n",
      "Epoch 5/10\n",
      "2846/2846 [==============================] - 24s 9ms/step - loss: 0.0844\n",
      "Epoch 6/10\n",
      "2846/2846 [==============================] - 24s 9ms/step - loss: 0.0797\n",
      "Epoch 7/10\n",
      "2846/2846 [==============================] - 24s 9ms/step - loss: 0.0753\n",
      "Epoch 8/10\n",
      "2846/2846 [==============================] - 25s 9ms/step - loss: 0.0703\n",
      "Epoch 9/10\n",
      "2846/2846 [==============================] - 25s 9ms/step - loss: 0.0663\n",
      "Epoch 10/10\n",
      "2846/2846 [==============================] - 25s 9ms/step - loss: 0.0619\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.0, 22.0, 16.0, 22.0, 30.0]\n",
      "Average Score: 20.2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'choices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-682d86bbc02c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average Score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'choice 1:{}  choice 0:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'choices' is not defined"
     ]
    }
   ],
   "source": [
    "#Testowanie\n",
    "scores = []\n",
    "#choices = []\n",
    "for each_game in range(5):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(5000):\n",
    "        env.render()\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randint(1,3)\n",
    "        else:\n",
    "            action = np.argmax(agent.model.predict(prev_obs))+1\n",
    "        \n",
    "        #choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = preprocess_frame(new_observation)\n",
    "        score+=reward\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "\n",
    "print(scores)\n",
    "print('Average Score:', sum(scores)/len(scores))\n",
    "print('choice 1:{}  choice 0:{}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4464, 4425, 4404, 4410, 4443, 4429, 4433, 4406, 4459, 4447, 4414, 4438, 4484, 4421, 4426, 4438, 4447, 4452, 4463, 4453]\n",
      "Average Score: 4437.8\n"
     ]
    }
   ],
   "source": [
    "#Dla porównania losowe ruchy\n",
    "scores = []\n",
    "#choices = []\n",
    "for each_game in range(20):\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    for step_index in range(goal_steps):\n",
    "        #env.render()\n",
    "        action = random.randrange(0,8)\n",
    "        \n",
    "        #choices.append(action)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        score+=1\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    scores.append(score)\n",
    "\n",
    "print(scores)\n",
    "print('Average Score:', sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
